# ğŸš¢ Titanic ETL with MySQL

## ğŸ“Œ What this Project Does

This project demonstrates a simple ETL (Extract, Transform, Load) pipeline using the Titanic dataset:

- ğŸ” **Extract**: Reads Titanic CSV data using Pandas  
- ğŸ§¹ **Transform**: Cleans data (handles missing values, fixes types)  
- ğŸ—„ï¸ **Load**: Loads the cleaned data into a MySQL database table

This is a part of my Data Engineering learning journey.

---

## ğŸ›  Tools Used

- Python
- Pandas
- SQLAlchemy
- MySQL

---


## ğŸ“‚ How to Run the Script

### 1. ğŸ›  Prerequisites

Make sure you have the following installed:
- Python 3.10+ (3.12 tested)
- MySQL installed and running

### 2. ğŸ§ª Create the MySQL Database
Before running the notebook, create a MySQL database called etl_demo:
  ```
CREATE DATABASE etl_demo;
```
### 3. ğŸ“ Update Credentials in Notebook
In the notebook, update your connection settings:
```
conn = mysql.connector.connect(
    host="localhost",
    user="root",
    password="your_password",  # change this
    database="etl_demo"
)
```
### 4. â–¶ï¸ Run the Jupyter Notebook
Open and run the cells in titanic_etl_mysql.ipynb. It will:

Create the titanic table (if not exists)

Insert cleaned rows into the table

## Author
Maherin Shaik
Aspiring Data Engineer

